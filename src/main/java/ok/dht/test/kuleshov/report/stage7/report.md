# Отчет Stage 7 Bonus
Консистентное хэширование с добавлением и удалением узлов и переносом ключей без перезапуска кластера.
Реализация весьма простая и предполагает изменение кластера по одной ноде.

## Взаимодействие с программой

Первое для данного проекта для запуска нужно заменить в ```build.gradle``` ```mainClass``` на ```'ok.dht.test.kuleshov.Server'```

Опции:
1. ```-p <port>``` указывает на каком локальном порту запускается сервер.
2. ```-a``` указывает что это узел, который запускается является новым уже в существующем кластере 
вместе с ним обязательно указывается опция -u.
3. ```-u <url>``` указывает у какого узла необходимо запросить текущую конфигурацию кластера.`
4. ```-h  <hash1> <hash2> ...``` опциональный параметр указывает какие хэши (через пробел) необходимо соотнести виртуальным узлам новой ноды.
Если не указан, то по дефолу генерируется 4 по алгоритму ниже.

Запускается командой ```gradle run --args="<опции>"```

Примеры:
1. Запуск первого узла ```gradle run --args="-p 19234"```
2. Запуск второго узла в готовый кластер ```gradle run --args="-a -u http://localhost:19234 -p 19666"```
3. Запуск второго узла в готовый кластер c виртуальными нодами с хэшами 0 и 1000
4. ```gradle run --args="-a -u http://localhost:19666 -p 19667 -h 0 1000"```

Дополнительное HTTP API:
1. ```/v0/maindeletenode``` удаляет узел на который отправлен запрос из кластера, т.е. 
```
curl --location -v --request GET 'http://localhost:19666/v0/maindeletenode' --header 'Content-Type: text/plain'
```
удалит узел ```http://localhost:19666``` из его кластера.
2. ```/v0/cluster-config``` запрашивает текущую конфигурацию класстера, пример 
```
curl --location -v --request GET 'http://localhost:19666/v0/cluster-config' --header 'Content-Type: text/plain'
```
может вернуть такой json
```
{"urlToHash":{"http://localhost:19234":[1894906372,-1217789564,-511636176,286163921],"http://localhost:19666":[-898821511,1244601444,-2112654767,-204944282]}}
```

## Консистентное хеширование
![img.png](img.png)


Метод распределения ключей по узлам кластера, где каждому узлу соответсвтует отрезок на окружности, сама окружность
от ```Integer.MIN_VALUE``` до ```Integer.MAX_VALUE```. А расположение ключа на окружности определяется по хешу ключа,
в моей реализации используется Hash.murmur3. Распределение отрезков между узлами определяется с учетом виртуальных нод
считается ```Hash.murmur3(<url узла> + "|" + i)```, где i - номер виртуальной ноды и далее этому узлу достается отрезок 
от минимального хэша других нод до высчитанного хэша.
## Добавление узла
Реализованно путем запуска сервера, который затем запрашивает у указанного узла конфигурацию кластера.
Запущенный узел добавляет узел в свою конфигурацию, затем отправляет всем остальным узлам сообщение о добавлении
нового узла, когда новый узел получает такое сообщение, он добавляет в свою конфигурацию и по необходимости передает 
ключи новому узлу, блокируя (отвечая 504) все операции по передаваемому отрезку до конца передачи, после конца передачи,
отправляется сообщение о конце, после чего новый узел может отвечать на запросы по этому отрезку.

По дефолту создается 4 виртуальных узла для одного реального по алгоритму из пункта выше. Но есть и возможность ручного 
выбора хэшей для вставки узла, то есть выбора места на окружности для вставки узла, что позволит вручную распределять
нагрузку между узлами. И например можно таким образом снять нагрузку с более слабых или более нагруженных узлов, добавив
новый узел или просто добавив виртуальную ноду.
## Удаление узла
Удаление происходит аналогично добавлению, но удаление происходит по определенному запросу к удаляемому узлу, далее
он отправляет запросы удаления себя остальным узлам класстера. После этого запускается перенос ключей, после которого
можно отключать узел.
## Перенос ключей
Перенос ключей осуществляется с помощью двух сервисов ```TransferSenderService``` и ```TransferReceiverService``` 
для отправки и приема ключей соответсвенно. Во время переноса блокируется весь переносимый отрезок,
во избежания создания различий в данных. Перенос происходит последовательно. Так как распределние по нодам использует 
хэш, то необходимо прочтение всех ключей ноды отправителя. Можно было бы оптимизировать это добавлением поля хэша
и некоторого индекса по этому полю, тогда можно было бы сразу перебирать только ключи, входящие в переносимый отрезок.
## Вывод
Модификация позволяет добавлять и удалять узлы, более точно рапределяя нагрузку по узлам кластера, однако стоит
доработать перенос, блокируя меньшее количество ключей используя блокировки на конкретные ключи
и использовать Chunked transfer encoding для более быстрой отправки.